{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Dataset Buildout - 12/12/25\n",
    "\n",
    "- All \"Self Help\" books & all \"Nonfiction\" books that also include key genres\n",
    "    - Exclude Textbooks, Reference\n",
    "    - English language only\n",
    "---\n",
    "- Zero-shot classification\n",
    "    - ChatGPT:\n",
    "        - Kinda need to determine if it addresses problems AT ALL for nonfiction (people are afflicted by [something])... then filter out any that don't ascribe to this\n",
    "        - Tony-robbins vs. wellbeing/mental health — something regarding \n",
    "    - ~~internal vs. external~~\n",
    "- Zero-shot:\n",
    "    - spiritual vs. secular\n",
    "    - mental vs. physical\n",
    "    - categories of DSM typoe things (anxiety spikes over time?)\n",
    "    - sub-categories of Self Help genres\n",
    "- DANIEL - Mental health piece... how has it been referred to in the past? Medical grounding? Today it's covered by insurance companies — they have created standardized plans. \n",
    "- Labels: Popular\n",
    "- Add Year col\n",
    "- World events same year\n",
    "- World events 1-5 years prior\n",
    "- Return structured data from URL\n",
    "    - Extract 'want to read', 'currently reading' and 'author bio'\n",
    "- JSON capture from Wikipedia Article on Book? Then Author?\n",
    "    - Identify inspirations in the form of other events\n",
    "- based on relevant prompts to create labeling conventions, use GPT API (or Gemini? Something free?) to assign relevent labels based on descriptions\n",
    "- standardize THREE datasets where possible:\n",
    "    1. Goodreads (and analysis)\n",
    "    2. Historical events\n",
    "    3. Wikipedia data (if needed)\n",
    "    4. Medical language?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "# pip install langdetect\n",
    "from langdetect import detect  # Comment out until package is installed\n",
    "from transformers import pipeline\n",
    "import ast\n",
    "# import os\n",
    "import ast\n",
    "# import openai\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"filtered_books_sample_0211.csv\")\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories = [\"personal development\", \"relationships\", \"psychology\", \"business\", \"memoir\", \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Language detection error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_goodreads(url):\n",
    "    data = {}\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            logging.error(f\"Request failed with status code {response.status_code} for URL {url}\")\n",
    "            return data\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Get image URL from the element with class \"BookCard\"\n",
    "        book_card = soup.find(class_=\"BookCard\")\n",
    "        if book_card:\n",
    "            img_tag = book_card.find(\"img\")\n",
    "            if img_tag and img_tag.get(\"src\"):\n",
    "                data[\"img_url\"] = img_tag[\"src\"]\n",
    "\n",
    "        # Extract author_text from <span class=\"Formatted\"> within the desired parent containers\n",
    "        page_section = soup.find(\"div\", class_=\"PageSection\")\n",
    "        if page_section:\n",
    "            details_div = page_section.find(\"div\", class_=\"DetailsLayoutRightParagraph__widthConstrained\")\n",
    "            if details_div:\n",
    "                author_span = details_div.find(\"span\", class_=\"Formatted\")\n",
    "                if author_span:\n",
    "                    data[\"author_text\"] = author_span.get_text(strip=True)\n",
    "\n",
    "        # Extract social signals from SocialSignalsSection__container\n",
    "        social_container = soup.find(class_=\"SocialSignalsSection__container\")\n",
    "        logging.info(f\"Social container found for URL {url}: {social_container is not None}\")\n",
    "        if social_container:\n",
    "            signals = social_container.find_all(\"div\", class_=\"SocialSignalsSection__caption\")\n",
    "            if signals and len(signals) >= 2:\n",
    "                # The first element is currently reading, second is to-read\n",
    "                curr_text = signals[0].get_text()\n",
    "                to_read_text = signals[1].get_text()\n",
    "                curr_match = re.search(r'([\\d,]+)', curr_text)\n",
    "                to_read_match = re.search(r'([\\d,]+)', to_read_text)\n",
    "                if curr_match:\n",
    "                    currently_reading = int(curr_match.group(1).replace(',', ''))\n",
    "                    data[\"currently_reading\"] = currently_reading\n",
    "                    print(f\"Currently reading count for {url}: {currently_reading}\")\n",
    "                if to_read_match:\n",
    "                    to_read = int(to_read_match.group(1).replace(',', ''))\n",
    "                    data[\"to_read\"] = to_read\n",
    "                    print(f\"To-read count for {url}: {to_read}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping {url}: {e}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def analyze_external_relevance(candidate_text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # Ensure this is a valid model identifier\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert literary analyst.\"},\n",
    "                {\"role\": \"user\", \"content\": (\n",
    "                    \"Does the following text explore forces, ideas, or subjects that impact human physical or mental health? \"\n",
    "                    \"Answer 'yes' or 'no' only.\\n\\nText:\\n\" + candidate_text\n",
    "                )}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip().lower()\n",
    "        logging.info(f\"OpenAI answer: {answer}\")\n",
    "        if answer == \"yes\":\n",
    "            return True\n",
    "        elif answer == \"no\":\n",
    "            return False\n",
    "        else:\n",
    "            logging.warning(f\"Unexpected answer from OpenAI: {answer}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"OpenAI API error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/318028.Il_Gigante: True\n",
      "  2%|▏         | 1/50 [00:03<02:57,  3.62s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/310054.Final_Analysis: True\n",
      "  4%|▍         | 2/50 [00:06<02:31,  3.15s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no.\n",
      "WARNING: Unexpected answer from OpenAI: no.\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/542884.Breaking_Loose_Together: True\n",
      "  6%|▌         | 3/50 [00:08<01:56,  2.48s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no.\n",
      "WARNING: Unexpected answer from OpenAI: no.\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/29769775-db-cooper-and-the-fbi: True\n",
      "  8%|▊         | 4/50 [00:10<02:00,  2.63s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/13631780-an-eye-for-an-eye: True\n",
      " 10%|█         | 5/50 [00:12<01:40,  2.24s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/558007.Dance_with_the_Devil: True\n",
      " 12%|█▏        | 6/50 [00:15<01:48,  2.46s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no.\n",
      "WARNING: Unexpected answer from OpenAI: no.\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/314941.Heidegger: True\n",
      " 14%|█▍        | 7/50 [00:17<01:39,  2.31s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/43371.No_One_Left_To_Lie_To: True\n",
      " 16%|█▌        | 8/50 [00:19<01:30,  2.16s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/489046.Jane_Austen_and_Food: True\n",
      " 18%|█▊        | 9/50 [00:25<02:26,  3.56s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/308227.Basic_Econometrics: True\n",
      " 20%|██        | 10/50 [00:28<02:12,  3.31s/it]INFO: Social container found for URL https://www.goodreads.com/book/show/6158679-my-anxious-mind: True\n",
      " 22%|██▏       | 11/50 [00:32<02:13,  3.41s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/320142.Straight_Talk_about_Psychiatric_Medications_for_Kids: True\n",
      " 24%|██▍       | 12/50 [00:35<02:06,  3.34s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no.\n",
      "WARNING: Unexpected answer from OpenAI: no.\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/26833512-the-flying-kangaroo: True\n",
      " 26%|██▌       | 13/50 [00:38<01:58,  3.20s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/12997794-biomimicry-in-architecture: True\n",
      " 28%|██▊       | 14/50 [00:41<01:58,  3.30s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/6571987-search-engines: True\n",
      " 30%|███       | 15/50 [00:43<01:40,  2.88s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/805610.Mao_for_Beginners: True\n",
      " 32%|███▏      | 16/50 [00:46<01:34,  2.78s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/828449.The_Jews_of_Islam: True\n",
      " 34%|███▍      | 17/50 [00:48<01:21,  2.47s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/263817.Ancient_Egypt: True\n",
      " 36%|███▌      | 18/50 [00:50<01:17,  2.42s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/6288967-grow-your-own-drugs: True\n",
      " 38%|███▊      | 19/50 [00:53<01:22,  2.68s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/6800430-write-to-sell: True\n",
      " 40%|████      | 20/50 [00:56<01:24,  2.82s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no.\n",
      "WARNING: Unexpected answer from OpenAI: no.\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/15820216-the-study-quran: True\n",
      " 42%|████▏     | 21/50 [01:00<01:29,  3.07s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/1305805.The_Gheranda_Samhita: True\n",
      " 44%|████▍     | 22/50 [01:02<01:20,  2.88s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/21151157-smell-of-summer-grass: True\n",
      " 46%|████▌     | 23/50 [01:05<01:13,  2.70s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes.\n",
      "WARNING: Unexpected answer from OpenAI: yes.\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/5983590-on-moving: True\n",
      " 48%|████▊     | 24/50 [01:07<01:06,  2.56s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/526049.Walt_Disney: True\n",
      " 50%|█████     | 25/50 [01:10<01:11,  2.85s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/14173666-women-serial-killers-of-the-19th-century---volume-2: True\n",
      " 52%|█████▏    | 26/50 [01:12<01:01,  2.58s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/597998.The_Bee_Tree: True\n",
      " 54%|█████▍    | 27/50 [01:17<01:10,  3.06s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/7383785-health-psychology: True\n",
      " 56%|█████▌    | 28/50 [01:19<01:01,  2.81s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/769544.Aching_for_Beauty: True\n",
      " 58%|█████▊    | 29/50 [01:22<00:58,  2.81s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/20588663-black-prophetic-fire: True\n",
      " 60%|██████    | 30/50 [01:25<00:58,  2.92s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/551280.Last_Night_I_Dreamed_of_Peace: True\n",
      " 62%|██████▏   | 31/50 [01:27<00:52,  2.78s/it]INFO: Social container found for URL https://www.goodreads.com/book/show/82094.Believe_and_Achieve: True\n",
      " 64%|██████▍   | 32/50 [01:30<00:50,  2.83s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/413799.Ecological_Revolutions: True\n",
      " 66%|██████▌   | 33/50 [01:33<00:46,  2.74s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/32319987-long-tall-lincoln: True\n",
      " 68%|██████▊   | 34/50 [01:36<00:44,  2.76s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no.\n",
      "WARNING: Unexpected answer from OpenAI: no.\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/479118.Feminism_and_Art_History: True\n",
      " 70%|███████   | 35/50 [01:37<00:36,  2.44s/it]INFO: Record 35 skipped: Non-English summary\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/21057848-million-dollar-launch: True\n",
      " 74%|███████▍  | 37/50 [01:40<00:23,  1.84s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/596314.One_Nation_Two_Cultures: True\n",
      " 76%|███████▌  | 38/50 [01:42<00:25,  2.13s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/1890163.White_Heat: True\n",
      " 78%|███████▊  | 39/50 [01:45<00:24,  2.19s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/474285.My_Lai: True\n",
      " 80%|████████  | 40/50 [01:47<00:21,  2.12s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/466537.Future_Shock: True\n",
      " 82%|████████▏ | 41/50 [01:49<00:20,  2.22s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/6238624-wildflower: True\n",
      " 84%|████████▍ | 42/50 [01:53<00:20,  2.58s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/1106474.The_Death_of_a_President: True\n",
      " 86%|████████▌ | 43/50 [01:56<00:19,  2.86s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: yes\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/6029333-holding-juno: True\n",
      " 88%|████████▊ | 44/50 [01:58<00:15,  2.61s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no.\n",
      "WARNING: Unexpected answer from OpenAI: no.\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/2223353.The_Orthodox_Study_Bible: True\n",
      " 90%|█████████ | 45/50 [02:01<00:12,  2.53s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/17287021-the-simpsons-and-their-mathematical-secrets: True\n",
      " 92%|█████████▏| 46/50 [02:04<00:10,  2.67s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/1515556.Bali: True\n",
      " 94%|█████████▍| 47/50 [02:06<00:07,  2.50s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/23787705-the-operators: True\n",
      " 96%|█████████▌| 48/50 [02:08<00:04,  2.49s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/363661.Atomic_Diplomacy: True\n",
      " 98%|█████████▊| 49/50 [02:10<00:02,  2.16s/it]INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: OpenAI answer: no\n",
      "INFO: Social container found for URL https://www.goodreads.com/book/show/6203202-communism: True\n",
      "100%|██████████| 50/50 [02:12<00:00,  2.65s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(df.head(50).iterrows(), total=50):\n",
    "    record_updates = {}\n",
    "    try:\n",
    "        summary = row.get(\"summary\", \"\")\n",
    "        genres = row.get(\"genres\", \"[]\")\n",
    "        \n",
    "        # Skip if non-English based on summary language detection\n",
    "        if not is_english(summary):\n",
    "            logging.info(f\"Record {idx} skipped: Non-English summary\")\n",
    "            continue\n",
    "        \n",
    "        # Parse genres (if stored as a string representation of a list)\n",
    "        try:\n",
    "            genres_list = ast.literal_eval(genres) if isinstance(genres, str) else genres\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error parsing genres for record {idx}: {e}\")\n",
    "            genres_list = []\n",
    "        \n",
    "        # Prepare candidate text for classification\n",
    "        candidate_text = summary + \" \" + \" \".join(genres_list)\n",
    "        \n",
    "        # Check if the book is labeled as Self Help\n",
    "        is_self_help = \"Self Help\" in genres_list\n",
    "        \n",
    "        if is_self_help:\n",
    "            # Use zero-shot classification to assign a Self Help subcategory\n",
    "            result = classifier(candidate_text, subcategories)\n",
    "            subcategory = result[\"labels\"][0]  # highest scoring label\n",
    "            record_updates[\"self_help_subcategory\"] = subcategory\n",
    "        else:\n",
    "            # Use OpenAI's LLM to determine relevance for external, health-impacting forces\n",
    "            record_updates[\"relevant_non_self_help\"] = analyze_external_relevance(candidate_text)\n",
    "        \n",
    "        # Generate spectrum labels using zero-shot classification\n",
    "        # Spectrum 1: Spiritual vs Secular\n",
    "        spiritual_labels = [\"spiritual\", \"secular\"]\n",
    "        result_spiritual = classifier(candidate_text, spiritual_labels)\n",
    "        p_spiritual = result_spiritual[\"scores\"][result_spiritual[\"labels\"].index(\"spiritual\")]\n",
    "        p_secular = result_spiritual[\"scores\"][result_spiritual[\"labels\"].index(\"secular\")]\n",
    "        total = p_spiritual + p_secular\n",
    "        record_updates[\"spiritual_score\"] = p_spiritual / total if total else None\n",
    "        \n",
    "        # Spectrum 2: Mental Health vs Physical Health\n",
    "        health_labels = [\"mental health\", \"physical health\"]\n",
    "        result_health = classifier(candidate_text, health_labels)\n",
    "        p_mental = result_health[\"scores\"][result_health[\"labels\"].index(\"mental health\")]\n",
    "        p_physical = result_health[\"scores\"][result_health[\"labels\"].index(\"physical health\")]\n",
    "        total = p_mental + p_physical\n",
    "        record_updates[\"mental_health_score\"] = p_mental / total if total else None\n",
    "        \n",
    "        # Scrape Goodreads page for additional info\n",
    "        url = row.get(\"url\", \"\")\n",
    "        if url:\n",
    "            scraped = scrape_goodreads(url)\n",
    "            record_updates.update(scraped)\n",
    "        \n",
    "        # Update the dataframe with new data for this record\n",
    "        for key, value in record_updates.items():\n",
    "            df.at[idx, key] = value\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing record {idx}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARCHIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import transformers  # Note: \"transforcers\" as mentioned in the instructions; using the transformers library\n",
    "\n",
    "# # Load the CSV into a DataFrame\n",
    "# df = pd.read_csv(\"filtered_books_sample_0211.csv\")\n",
    "# print(\"Loaded initial dataset with\", len(df), \"records\")\n",
    "\n",
    "# # Filter for books with 200+ ratings\n",
    "# df = df[df[\"num_ratings\"] >= 200]\n",
    "# print(\"Filtered to\", len(df), \"books with 200+ ratings\")\n",
    "\n",
    "# # Identify records where the \"genres\" column includes \"Nonfiction\"\n",
    "# nonfiction_mask = df[\"genres\"].str.contains(\"Nonfiction\", case=False, na=False)\n",
    "# print(\"Found\", nonfiction_mask.sum(), \"nonfiction books\")\n",
    "\n",
    "# # Set up the zero-shot classification pipeline using the transformers library\n",
    "# pipe = transformers.pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "# print(\"Initialized classification pipeline\")\n",
    "\n",
    "# # Define candidate labels for classification\n",
    "# candidate_labels = [\"addresses a human problem\", \"does not address a human problem\"]\n",
    "\n",
    "# # Set a threshold: if the score for \"addresses a problem\" meets or exceeds this, we mark it True\n",
    "# threshold = 0.8\n",
    "\n",
    "# # Helper function to classify a book summary\n",
    "# def classify_summary(summary):\n",
    "#     result = pipe(summary, candidate_labels=candidate_labels)\n",
    "#     # The pipeline returns labels sorted by score (highest first)\n",
    "#     if result[\"labels\"][0] == \"addresses a problem\" and result[\"scores\"][0] >= threshold:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# # Apply the classification only on the first 50 filtered (Nonfiction) records and create the new column\n",
    "# nonfiction_mask_200 = nonfiction_mask & (df.index < 200)\n",
    "# print(\"Starting classification of\", nonfiction_mask_200.sum(), \"books...\")\n",
    "# df.loc[nonfiction_mask_200, \"addresses_problem\"] = df.loc[nonfiction_mask_200, \"summary\"].apply(classify_summary)\n",
    "# print(\"Classification complete!\")\n",
    "\n",
    "-----------------------------\n",
    "\n",
    "# for idx, row in tqdm(df.head(10).iterrows(), total=10):\n",
    "#     record_updates = {}\n",
    "#     try:\n",
    "#         summary = row.get(\"summary\", \"\")\n",
    "#         genres = row.get(\"genres\", \"[]\")\n",
    "        \n",
    "#         # Skip if non-English based on summary language detection\n",
    "#         if not is_english(summary):\n",
    "#             logging.info(f\"Record {idx} skipped: Non-English summary\")\n",
    "#             continue\n",
    "        \n",
    "#         # Parse genres (if stored as a string representation of a list)\n",
    "#         try:\n",
    "#             genres_list = ast.literal_eval(genres) if isinstance(genres, str) else genres\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error parsing genres for record {idx}: {e}\")\n",
    "#             genres_list = []\n",
    "        \n",
    "#         # Prepare candidate text for zero-shot classification\n",
    "#         candidate_text = summary + \" \" + \" \".join(genres_list)\n",
    "        \n",
    "#         # Check if the book is labeled as Self Help\n",
    "#         is_self_help = \"Self Help\" in genres_list\n",
    "        \n",
    "#         if is_self_help:\n",
    "#             # Self Help: Use zero-shot classification to assign a subcategory\n",
    "#             result = classifier(candidate_text, subcategories)\n",
    "#             subcategory = result[\"labels\"][0]  # highest scoring label\n",
    "#             record_updates[\"self_help_subcategory\"] = subcategory\n",
    "#         else:\n",
    "#             # Non-self-help: Determine relevance to health-impacting forces using zero-shot classification\n",
    "#             external_labels = [\"explores forces, ideas, or subjects that impact human physical or mental health\", \n",
    "#                              \"does not explore forces, ideas, or subjects that impact human physical or mental health\"]\n",
    "#             result_external = classifier(candidate_text, external_labels)\n",
    "#             score_explore = result_external[\"scores\"][result_external[\"labels\"].index(\"explores forces, ideas, or subjects that impact human physical or mental health\")]\n",
    "#             score_not_explore = result_external[\"scores\"][result_external[\"labels\"].index(\"does not explore forces, ideas, or subjects that impact human physical or mental health\")]\n",
    "#             # Mark as relevant if the score for exploring health-impacting forces is higher\n",
    "#             record_updates[\"relevant_non_self_help\"] = score_explore > score_not_explore\n",
    "        \n",
    "#         # Generate spectrum labels using zero-shot classification\n",
    "#         # Spectrum 1: Spiritual vs Secular\n",
    "#         spiritual_labels = [\"spiritual\", \"secular\"]\n",
    "#         result_spiritual = classifier(candidate_text, spiritual_labels)\n",
    "#         p_spiritual = result_spiritual[\"scores\"][result_spiritual[\"labels\"].index(\"spiritual\")]\n",
    "#         p_secular = result_spiritual[\"scores\"][result_spiritual[\"labels\"].index(\"secular\")]\n",
    "#         total = p_spiritual + p_secular\n",
    "#         record_updates[\"spiritual_score\"] = p_spiritual / total if total else None\n",
    "        \n",
    "#         # Spectrum 2: Mental Health vs Physical Health\n",
    "#         health_labels = [\"mental health\", \"physical health\"]\n",
    "#         result_health = classifier(candidate_text, health_labels)\n",
    "#         p_mental = result_health[\"scores\"][result_health[\"labels\"].index(\"mental health\")]\n",
    "#         p_physical = result_health[\"scores\"][result_health[\"labels\"].index(\"physical health\")]\n",
    "#         total = p_mental + p_physical\n",
    "#         record_updates[\"mental_health_score\"] = p_mental / total if total else None\n",
    "        \n",
    "#         # Scrape Goodreads page for additional info\n",
    "#         url = row.get(\"url\", \"\")\n",
    "#         if url:\n",
    "#             scraped = scrape_goodreads(url)\n",
    "#             record_updates.update(scraped)\n",
    "        \n",
    "#         # Update the dataframe with new data for this record\n",
    "#         for key, value in record_updates.items():\n",
    "#             df.at[idx, key] = value\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error processing record {idx}: {e}\")\n",
    "#         continue\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
